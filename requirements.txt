# Requirements for Sequential Transfer Learning Experiments
# Deep learning framework and computer vision package dependencies
# Tested on NVIDIA GeForce RTX 5080 GPU (16GB VRAM)

# Core Deep Learning Frameworks
torch>=2.7.0
torchvision>=0.22.0
pytorch-lightning>=2.0.0,<3.0.0

# Model and Tokenizer Libraries
transformers>=4.40.0
timm>=0.9.0,<1.0.0
accelerate>=0.20.0,<1.0.0
safetensors>=0.3.0,<1.0.0

# HuggingFace Hub with XET storage support
huggingface-hub[hf_xet]>=0.20.0
hf_xet>=0.20.0

# Metrics and Evaluation
torchmetrics>=1.0.0,<2.0.0
scikit-learn>=1.3.0,<2.0.0

# FLOPs Calculation
fvcore>=0.1.5
thop>=0.1.1

# Visualization
matplotlib>=3.7.0,<4.0.0
seaborn>=0.12.0,<1.0.0
numpy>=1.24.0,<2.0.0

# Logging and Progress
tensorboard>=2.13.0,<3.0.0
rich>=13.0.0,<14.0.0
tqdm>=4.65.0,<5.0.0

# Image Processing and Data Handling
pillow>=9.5.0,<11.0.0

# Configuration and Utilities
pyyaml>=6.0,<7.0
psutil>=5.9.0,<6.0.0

# Code Quality and Development Tools
black==24.2.0
pylint==3.1.0
ruff==0.3.3
typeguard==4.1.5

# Hyperparameter Optimization
optuna==3.5.0
optuna-dashboard==0.15.1
statsmodels==0.14.1

# Installation Instructions
# 
# Step 1: Install PyTorch with CUDA support first
# Run one of these commands based on your system:
#
# For CUDA 13.1 (RTX 50 series - tested on RTX 5080 Laptop GPU):
#   pip3 install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128
#
# For CUDA 12.8 (alternative for RTX 50 series):
#   pip3 install torch==2.7.0 torchvision==0.22.0 --index-url https://download.pytorch.org/whl/cu128
#
# For CUDA 12.4 (RTX 40 series):
#   pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu124
#
# For CUDA 11.8 (older GPUs):
#   pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118
#
# For CPU only (not recommended for training):
#   pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cpu
#
# Step 2: Install remaining requirements
#   pip install -r requirements.txt
#
# Verification
# Check PyTorch installation:
#   python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
#
# Check CUDA version and GPU:
#   python -c "import torch; print('CUDA:', torch.version.cuda); print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None')"
#
# Check transformers:
#   python -c "import transformers; print(transformers.__version__)"
#
# Version Notes
# PyTorch 2.7.0 or higher is required for RTX 50-series GPU support
# CUDA 12.8+ or 13.1+ required for Blackwell architecture (sm_120)
# Transformers 4.40.0 or higher is required for compatibility with PyTorch 2.7+
# Python 3.10 or 3.11 is recommended for best compatibility
#
# Hardware Specifications
# All experiments conducted on NVIDIA GeForce RTX 5080 Laptop GPU
# - VRAM: 16GB GDDR7
# - Compute Capability: 12.0 (Blackwell architecture)
# - Driver Version: 590.44+ recommended
# - CUDA Version: 13.1
#
# Troubleshooting
# If CUDA is not detected after installation, verify NVIDIA drivers are installed.
# For RTX 50-series GPUs, ensure driver version 590.00 or higher is installed.
# The PyTorch CUDA version does not need to match your system CUDA installation exactly.
# If encountering "sm_120 not supported" errors, use PyTorch nightly builds or wait for
# official stable release with Blackwell support.